{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd2339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a040e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega arquivo parquet\n",
    "df = pd.read_parquet(\"DB/List-dependencies.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38732111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "graphs = {}\n",
    "dfs[\"Geral\"] = df\n",
    "graphs[\"Geral\"] = nx.from_pandas_edgelist(df, source=\"Project Name\", target=\"Dependency Name\", create_using=nx.DiGraph())\n",
    "for platform in df[\"Platform\"].unique():\n",
    "    # cria um dataframe para cada plataforma \"df[\"Platform\"].unique()\" e adiciona a lista de dataframes ao dicionário \"dfs\"\n",
    "    dfs[platform] = df[df[\"Platform\"] == platform]\n",
    "\n",
    "    # Cria um grafo direcionado\n",
    "    graphs[platform] = nx.from_pandas_edgelist(dfs[platform], source=\"Project Name\", target=\"Dependency Name\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise para o grafo: Geral...\n",
      "  Calculando PageRank em 200,000 nós...\n",
      "  Calculando Betweenness (aproximado com k=1000)...\n",
      "Análise de Geral concluída em 1632.50 segundos.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ea45f16bc447f0b8d7906040d09ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analisando Plataformas:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise para o grafo: Atom...\n",
      "  Calculando PageRank em 6,770 nós...\n",
      "  Calculando Betweenness em 6,770 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Atom concluída em 293.65 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: CPAN...\n",
      "  Calculando PageRank em 32,898 nós...\n",
      "  Calculando Betweenness em 32,898 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de CPAN concluída em 7938.59 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: CRAN...\n",
      "  Calculando PageRank em 15,409 nós...\n",
      "  Calculando Betweenness em 15,409 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de CRAN concluída em 1819.06 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Cargo...\n",
      "  Calculando PageRank em 23,951 nós...\n",
      "  Calculando Betweenness em 23,951 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Cargo concluída em 4051.54 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Conda...\n",
      "  Calculando PageRank em 959 nós...\n",
      "  Calculando Betweenness em 959 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Conda concluída em 8.21 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Dub...\n",
      "  Calculando PageRank em 780 nós...\n",
      "  Calculando Betweenness em 780 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Dub concluída em 1.14 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Elm...\n",
      "  Calculando PageRank em 1,474 nós...\n",
      "  Calculando Betweenness em 1,474 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Elm concluída em 3.89 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Haxelib...\n",
      "  Calculando PageRank em 500 nós...\n",
      "  Calculando Betweenness em 500 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Haxelib concluída em 0.40 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Hex...\n",
      "  Calculando PageRank em 5,403 nós...\n",
      "  Calculando Betweenness em 5,403 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Hex concluída em 175.93 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Homebrew...\n",
      "  Calculando PageRank em 2,023 nós...\n",
      "  Calculando Betweenness em 2,023 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Homebrew concluída em 11.46 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: Maven...\n",
      "  Calculando PageRank em 116,772 nós...\n",
      "  Calculando Betweenness em 116,772 nós...\n",
      "  Calculando Coeficiente de Clusterização...\n",
      "  Detectando comunidades (Louvain)...\n",
      "Análise de Maven concluída em 100174.68 segundos.\n",
      "\n",
      "Iniciando análise para o grafo: NPM...\n",
      "  Calculando PageRank em 1,022,526 nós...\n",
      "  Calculando Betweenness em 1,022,526 nós...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from networkx.algorithms import community\n",
    "\n",
    "def format_report(graph_name, metrics):\n",
    "    \"\"\"Formata as métricas coletadas em uma string Markdown.\"\"\"\n",
    "    report = [f\"# Análise do Grafo: {graph_name}\\n\"]\n",
    "    \n",
    "    # Métricas Básicas\n",
    "    report.append(\"## 1. Métricas Gerais\")\n",
    "    report.append(\"| Métrica | Valor |\")\n",
    "    report.append(\"|---|---|\")\n",
    "    report.append(f\"| **Nós (Projetos/Dependências)** | {metrics['nodes']:,} |\")\n",
    "    report.append(f\"| **Arestas (Dependências)** | {metrics['edges']:,} |\")\n",
    "    report.append(f\"| **Densidade do Grafo** | {metrics['density']:.8f} |\")\n",
    "    report.append(f\"| **Grafo Direcionado** | {'Sim' if metrics['is_directed'] else 'Não'} |\")\n",
    "    \n",
    "    # Conectividade\n",
    "    report.append(\"\\n## 2. Análise de Conectividade\")\n",
    "    report.append(\"| Métrica | Valor |\")\n",
    "    report.append(\"|---|---|\")\n",
    "    report.append(f\"| **Componentes Fracamente Conectados** | {metrics['wcc_count']:,} |\")\n",
    "    report.append(f\"| **Nós no Maior Componente (LCC)** | {metrics['lcc_nodes']:,} ({metrics['lcc_percent']:.2f}%) |\")\n",
    "    report.append(f\"| **Arestas no Maior Componente (LCC)** | {metrics['lcc_edges']:,} ({metrics['lcc_edges_percent']:.2f}%) |\")\n",
    "\n",
    "    # Análise de Graus\n",
    "    report.append(\"\\n## 3. Análise de Graus (Popularidade e Complexidade)\")\n",
    "    report.append(\"### 3.1. Estatísticas Gerais de Grau\")\n",
    "    report.append(\"| Métrica | In-Degree (Popularidade) | Out-Degree (Complexidade) | Grau Total |\")\n",
    "    report.append(\"|---|---|---|---|\")\n",
    "    report.append(f\"| **Média** | {metrics['in_degree_mean']:.2f} | {metrics['out_degree_mean']:.2f} | {metrics['degree_mean']:.2f} |\")\n",
    "    report.append(f\"| **Mediana** | {metrics['in_degree_median']:.2f} | {metrics['out_degree_median']:.2f} | {metrics['degree_median']:.2f} |\")\n",
    "    report.append(f\"| **Máximo** | {metrics['in_degree_max']:,} | {metrics['out_degree_max']:,} | {metrics['degree_max']:,} |\")\n",
    "\n",
    "    report.append(\"\\n### 3.2. Top 10 Dependências Mais Populares (Maior In-Degree)\")\n",
    "    report.append(\"| Rank | Dependência | In-Degree |\")\n",
    "    report.append(\"|---|---|---|\")\n",
    "    for i, (node, degree) in enumerate(metrics['top_in_degree'], 1):\n",
    "        report.append(f\"| {i} | `{node}` | {degree:,} |\")\n",
    "\n",
    "    report.append(\"\\n### 3.3. Top 10 Projetos Mais Complexos (Maior Out-Degree)\")\n",
    "    report.append(\"| Rank | Projeto | Out-Degree |\")\n",
    "    report.append(\"|---|---|---|\")\n",
    "    for i, (node, degree) in enumerate(metrics['top_out_degree'], 1):\n",
    "        report.append(f\"| {i} | `{node}` | {degree:,} |\")\n",
    "\n",
    "    # Centralidade\n",
    "    if 'pagerank' in metrics:\n",
    "        report.append(\"\\n## 4. Análise de Centralidade\")\n",
    "        report.append(f\"_(Análise realizada em {metrics.get('centrality_info', 'todo o grafo')})_\")\n",
    "        report.append(\"\\n### 4.1. Top 10 Nós por Influência (PageRank)\")\n",
    "        report.append(\"| Rank | Nó | PageRank Score |\")\n",
    "        report.append(\"|---|---|---|\")\n",
    "        for i, (node, score) in enumerate(metrics['pagerank'], 1):\n",
    "            report.append(f\"| {i} | `{node}` | {score:.6f} |\")\n",
    "        \n",
    "        if 'betweenness' in metrics:\n",
    "            report.append(\"\\n### 4.2. Top 10 Nós por Importância Estrutural (Betweenness Centrality)\")\n",
    "            report.append(\"| Rank | Nó | Betweenness Score |\")\n",
    "            report.append(\"|---|---|---|\")\n",
    "            for i, (node, score) in enumerate(metrics['betweenness'], 1):\n",
    "                report.append(f\"| {i} | `{node}` | {score:.6f} |\")\n",
    "\n",
    "    # Análise Estrutural\n",
    "    if 'avg_clustering' in metrics:\n",
    "        report.append(\"\\n## 5. Análise Estrutural e de Comunidades\")\n",
    "        report.append(f\"| Métrica | Valor |\")\n",
    "        report.append(f\"|---|---|\")\n",
    "        report.append(f\"| **Coeficiente de Clusterização Médio** | {metrics['avg_clustering']:.6f} |\")\n",
    "        if 'communities' in metrics:\n",
    "            report.append(f\"| **Comunidades Detectadas (Louvain)** | {metrics['communities']:,} |\")\n",
    "            report.append(f\"| **Modularidade** | {metrics['modularity']:.4f} |\")\n",
    "\n",
    "    report.append(f\"\\n---\\n*Análise concluída em {metrics['elapsed_time']:.2f} segundos.*\\n\\n\")\n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "\n",
    "def analyze_graph(graph, name, is_large_scale=False):\n",
    "    \"\"\"Função principal para analisar um grafo e coletar métricas.\"\"\"\n",
    "    print(f\"Iniciando análise para o grafo: {name}...\")\n",
    "    start_time = time.time()\n",
    "    metrics = {}\n",
    "\n",
    "    # 1. Métricas Básicas\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    num_edges = graph.number_of_edges()\n",
    "    metrics.update({\n",
    "        'nodes': num_nodes,\n",
    "        'edges': num_edges,\n",
    "        'density': nx.density(graph),\n",
    "        'is_directed': graph.is_directed()\n",
    "    })\n",
    "\n",
    "    if num_nodes == 0:\n",
    "        metrics['elapsed_time'] = time.time() - start_time\n",
    "        return metrics\n",
    "\n",
    "    # 2. Conectividade\n",
    "    wcc = list(nx.weakly_connected_components(graph))\n",
    "    largest_wcc_nodes = max(wcc, key=len)\n",
    "    lcc = graph.subgraph(largest_wcc_nodes)\n",
    "    metrics.update({\n",
    "        'wcc_count': len(wcc),\n",
    "        'lcc_nodes': lcc.number_of_nodes(),\n",
    "        'lcc_percent': (lcc.number_of_nodes() / num_nodes) * 100 if num_nodes > 0 else 0,\n",
    "        'lcc_edges': lcc.number_of_edges(),\n",
    "        'lcc_edges_percent': (lcc.number_of_edges() / num_edges) * 100 if num_edges > 0 else 0,\n",
    "    })\n",
    "\n",
    "    # 3. Análise de Grau\n",
    "    in_degrees = dict(graph.in_degree())\n",
    "    out_degrees = dict(graph.out_degree())\n",
    "    degrees = dict(graph.degree())\n",
    "    metrics.update({\n",
    "        'in_degree_mean': np.mean(list(in_degrees.values())),\n",
    "        'in_degree_median': np.median(list(in_degrees.values())),\n",
    "        'in_degree_max': max(in_degrees.values() or [0]),\n",
    "        'out_degree_mean': np.mean(list(out_degrees.values())),\n",
    "        'out_degree_median': np.median(list(out_degrees.values())),\n",
    "        'out_degree_max': max(out_degrees.values() or [0]),\n",
    "        'degree_mean': np.mean(list(degrees.values())),\n",
    "        'degree_median': np.median(list(degrees.values())),\n",
    "        'degree_max': max(degrees.values() or [0]),\n",
    "        'top_in_degree': sorted(in_degrees.items(), key=lambda item: item[1], reverse=True)[:10],\n",
    "        'top_out_degree': sorted(out_degrees.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "    })\n",
    "\n",
    "    # 4. Centralidade (Otimizado para escala)\n",
    "    target_graph_for_centrality = lcc\n",
    "    if is_large_scale:\n",
    "        # Para grafos muito grandes, amostrar é mais seguro mesmo com muita RAM\n",
    "        sample_size = min(num_nodes, 200000) # Amostra grande de 200k nós\n",
    "        sample_nodes = np.random.choice(list(lcc.nodes()), sample_size, replace=False)\n",
    "        target_graph_for_centrality = lcc.subgraph(sample_nodes)\n",
    "        metrics['centrality_info'] = f\"uma amostra de {sample_size:,} nós do maior componente\"\n",
    "    \n",
    "    print(f\"  Calculando PageRank em {target_graph_for_centrality.number_of_nodes():,} nós...\")\n",
    "    pagerank = nx.pagerank(target_graph_for_centrality, alpha=0.85)\n",
    "    metrics['pagerank'] = sorted(pagerank.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "\n",
    "    # Betweenness é muito pesado. Para o grafo grande, usamos uma aproximação com k.\n",
    "    # Para os menores, calculamos no LCC inteiro.\n",
    "    if is_large_scale:\n",
    "        k_betweenness = min(1000, target_graph_for_centrality.number_of_nodes())\n",
    "        print(f\"  Calculando Betweenness (aproximado com k={k_betweenness})...\")\n",
    "        betweenness = nx.betweenness_centrality(target_graph_for_centrality, k=k_betweenness, normalized=True)\n",
    "        metrics['centrality_info'] += f\" (Betweenness aproximado com k={k_betweenness})\"\n",
    "    else:\n",
    "        print(f\"  Calculando Betweenness em {target_graph_for_centrality.number_of_nodes():,} nós...\")\n",
    "        betweenness = nx.betweenness_centrality(target_graph_for_centrality, normalized=True)\n",
    "    metrics['betweenness'] = sorted(betweenness.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "\n",
    "    # 5. Análise Estrutural (Apenas para grafos menores, pois são caros)\n",
    "    if not is_large_scale:\n",
    "        print(\"  Calculando Coeficiente de Clusterização...\")\n",
    "        metrics['avg_clustering'] = nx.average_clustering(graph)\n",
    "        \n",
    "        print(\"  Detectando comunidades (Louvain)...\")\n",
    "        # O algoritmo de comunidade funciona melhor em grafos não direcionados\n",
    "        communities_sets = community.louvain_communities(graph.to_undirected(), seed=42)\n",
    "        modularity = community.modularity(graph.to_undirected(), communities_sets)\n",
    "        metrics.update({\n",
    "            'communities': len(communities_sets),\n",
    "            'modularity': modularity\n",
    "        })\n",
    "\n",
    "    metrics['elapsed_time'] = time.time() - start_time\n",
    "    print(f\"Análise de {name} concluída em {metrics['elapsed_time']:.2f} segundos.\\n\")\n",
    "    return metrics\n",
    "\n",
    "# --- Bloco Principal de Execução ---\n",
    "final_report_md = []\n",
    "\n",
    "# Analisa o grafo \"Geral\" com a estratégia para larga escala\n",
    "if \"Geral\" in graphs:\n",
    "    geral_metrics = analyze_graph(graphs[\"Geral\"], \"Geral\", is_large_scale=True)\n",
    "    final_report_md.append(format_report(\"Geral\", geral_metrics))\n",
    "\n",
    "# Analisa os outros grafos com a estratégia padrão\n",
    "sorted_platforms = sorted([p for p in graphs.keys() if p != \"Geral\"])\n",
    "for platform_name in tqdm(sorted_platforms, desc=\"Analisando Plataformas\"):\n",
    "    platform_graph = graphs[platform_name]\n",
    "    platform_metrics = analyze_graph(platform_graph, platform_name, is_large_scale=False)\n",
    "    final_report_md.append(format_report(platform_name, platform_metrics))\n",
    "\n",
    "# Salva o relatório final em um arquivo .md\n",
    "output_filename = \"analise_grafos.md\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(final_report_md))\n",
    "\n",
    "print(f\"Relatório completo salvo em: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
